{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "671637e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a71950a4",
   "metadata": {},
   "source": [
    "# Imbed DOG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "88e81b42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['misc', 'segments', 'embeddings', 'clusters', 'planar_embeddings']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from imbed.imbed_project import get_local_mall\n",
    "from i2 import AttributeMapping\n",
    "# TODO: Wrap in Iterable SimpleNamespace (from types import SimpleNamespace)\n",
    "mall = AttributeMapping(**get_local_mall('test'))\n",
    "list(mall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1db20e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "mall['segments']['hi'] = ['hello', 'world']\n",
    "assert mall['segments']['hi'] == ['hello', 'world']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a93b42d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vd.dog import DOG\n",
    "\n",
    "DOG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "12bbe0f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imbed import imbed_project\n",
    "\n",
    "mall = imbed_project.get_mall(\n",
    "        'dog_tests', get_project_mall=imbed_project.get_local_mall\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a8217bb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['misc',\n",
       " 'segments',\n",
       " 'embeddings',\n",
       " 'clusters',\n",
       " 'planar_embeddings',\n",
       " 'segmenters',\n",
       " 'embedders',\n",
       " 'clusterers',\n",
       " 'planarizers',\n",
       " 'segmenters_signatures',\n",
       " 'embedders_signatures',\n",
       " 'clusterers_signatures',\n",
       " 'planarizers_signatures']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(mall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ecab410f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/thorwhalen/.config/imbed/projects/spaces/dog_tests/stores/segments/'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mall.segments.rootdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "36d9010f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['segments_2', 'test', 'segments_1']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mall.segments['test'] = ['hello world', 'how are you?']\n",
    "list(mall.segments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f67f4024",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "622cc079",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "798c0ca2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6ae67b7f",
   "metadata": {},
   "source": [
    "# Dispatching a mesh\n",
    "\n",
    "A mesh is a DAG (acyclidc directed graph) that relates functions to other functions via their inputs and outputs. Dispatching a mesh has to do with wrapping it or transforming it into an object that will use it to operate. \n",
    "\n",
    "Here, we will consider a simple, yet real life, DAG, and transform it iteratively to enable the simple DAG to operate differently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f729b370",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tonal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "073f7d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Sequence, NewType, KT, Tuple, MutableMapping, Callable, Iterable\n",
    "\n",
    "Segment = NewType(\"Segment\", str)\n",
    "Embedding = NewType(\"Embedding\", Sequence[float])\n",
    "PlanarVector = Tuple[float, float]\n",
    "ClusterIndex = NewType(\"ClusterIndex\", int)\n",
    "\n",
    "Segments = Iterable[Segment]\n",
    "Embeddings = Iterable[Embedding]\n",
    "PlanarVectors = Iterable[PlanarVector]\n",
    "ClusterIndices = Iterable[ClusterIndex]\n",
    "\n",
    "Embedder = Callable[[Segments], Embeddings]\n",
    "Planarizer = Callable[[Embeddings], PlanarVectors]\n",
    "Clusterer = Callable[[Embeddings], ClusterIndices]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eace1d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Null:\n",
    "    def __getattr__(self, name): return self\n",
    "    def __setattr__(self, name, value): pass\n",
    "    def __getitem__(self, key): return self\n",
    "    def __setitem__(self, key, value): pass\n",
    "    def __call__(self, *args, **kwargs): return self\n",
    "    def __repr__(self): return \"Null()\"\n",
    "\n",
    "null = Null()\n",
    "\n",
    "mk_mesh_for_funcs = null\n",
    "\n",
    "\n",
    "from collections.abc import MutableMapping\n",
    "\n",
    "class AttrMapping(MutableMapping):\n",
    "    def __init__(self, mapping):\n",
    "        self._mapping = mapping  # no dict() copy\n",
    "\n",
    "    def __getitem__(self, key): return self._mapping[key]\n",
    "    def __setitem__(self, key, value): self._mapping[key] = value\n",
    "    def __delitem__(self, key): del self._mapping[key]\n",
    "    def __iter__(self): return iter(self._mapping)\n",
    "    def __len__(self): return len(self._mapping)\n",
    "\n",
    "    def __getattr__(self, key):\n",
    "        if key in self._mapping and key.isidentifier() and not hasattr(MutableMapping, key):\n",
    "            return self._mapping[key]\n",
    "        raise AttributeError(f\"No such attribute: {key}\")\n",
    "\n",
    "    def __setattr__(self, key, value):\n",
    "        if key.startswith(\"_\") or not key.isidentifier() or hasattr(MutableMapping, key):\n",
    "            super().__setattr__(key, value)\n",
    "        else:\n",
    "            self._mapping[key] = value\n",
    "\n",
    "    def __dir__(self):\n",
    "        return list(super().__dir__()) + [\n",
    "            k for k in self._mapping\n",
    "            if k.isidentifier() and not hasattr(MutableMapping, k)\n",
    "        ]\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8220abf6",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 83\u001b[0m\n\u001b[1;32m     70\u001b[0m mesh \u001b[38;5;241m=\u001b[39m mk_mesh_for_funcs(\n\u001b[1;32m     71\u001b[0m     funcs\u001b[38;5;241m=\u001b[39mfuncs, stored_types\u001b[38;5;241m=\u001b[39mstored_types\n\u001b[1;32m     72\u001b[0m )\n\u001b[1;32m     75\u001b[0m \u001b[38;5;66;03m# list(mesh.stores)\u001b[39;00m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;66;03m# # ['segments', 'embeddings', 'planar_vectors', 'cluster_indices']\u001b[39;00m\n\u001b[1;32m     77\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;66;03m# # ... so you get attribute access to the stores\u001b[39;00m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;66;03m# mesh.stores.segments == mesh.stores['segments']  \u001b[39;00m\n\u001b[0;32m---> 83\u001b[0m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmesh\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;66;03m# ['embedder', 'planarizer', 'clusterer']\u001b[39;00m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;66;03m# assert isinstance(mesh.func, AttrMapping)\u001b[39;00m\n\u001b[1;32m     86\u001b[0m mesh\u001b[38;5;241m.\u001b[39mfunc\u001b[38;5;241m.\u001b[39membedder\n",
      "Cell \u001b[0;32mIn[11], line 4\u001b[0m, in \u001b[0;36mNull.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, key): \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from typing import Callable\n",
    "from functools import partial \n",
    "\\\n",
    "from dol import Pipe \n",
    "\n",
    "vectorize = lambda func: Pipe(partial(map, func), list)\n",
    "# f = vectorize(lambda x: 2 * x)\n",
    "# f([1, 2, 3])  # [2, 4, 6]\n",
    "\n",
    "\n",
    "funcs = {\n",
    "    'embedder': Callable[[Segments], Embeddings],\n",
    "    'planarizer': Callable[[Embeddings], PlanarVectors],\n",
    "    'clusterer': Callable[[Embeddings, int], ClusterIndices],\n",
    "}\n",
    "val_stores = {\n",
    "    'segments': {\n",
    "        'type': Segments,\n",
    "        'store': {'segments_1': ['segment1', 'segment2', 'segment3'],\n",
    "                  'segments_2': ['segment4', 'segment5']\n",
    "        },\n",
    "    },\n",
    "    'embeddings': {\n",
    "        'type': Embeddings,\n",
    "        'store': dict(),\n",
    "    },\n",
    "    'planar_vectors': {\n",
    "        'type': PlanarVectors,\n",
    "        'store': dict(),\n",
    "    },\n",
    "    'cluster_indices': {\n",
    "        'type': ClusterIndices,\n",
    "        'store': dict(),\n",
    "    },\n",
    "}\n",
    "func_stores = {\n",
    "    'embedder': {\n",
    "        'name': 'embedders',\n",
    "        'store': {\n",
    "            'constant': lambda segments: vectorize(lambda s: [1, 2, 3])(segments),\n",
    "            'segment_based': lambda segments: vectorize(lambda s: [len(s), 0.5, 0.5])(segments),\n",
    "        },\n",
    "    },\n",
    "    'planarizer': {\n",
    "        'name': 'planarizers',\n",
    "        'store': {\n",
    "            'constant': lambda embeddings: vectorize(lambda e: (e[0], e[1]))(embeddings),\n",
    "            'embedding_based': lambda embeddings: vectorize(lambda e: (e[0] * 0.5, e[1] * 0.5))(embeddings),\n",
    "        },\n",
    "    },\n",
    "    ...\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "mesh = mk_mesh_for_funcs(\n",
    "    funcs=funcs, val_stores=val_stores, func_stores=func_stores\n",
    ")\n",
    "\n",
    "\n",
    "list(mesh.stores)\n",
    "# ['segments', 'embeddings', 'planar_vectors', 'cluster_indices']\n",
    "\n",
    "mesh.stores['segments'] == mesh.stores['segments']  \n",
    "\n",
    "sorted(mesh.stores['segments'])  # list the segments (keys)\n",
    "# ['segments_1', 'segments_2']\n",
    "\n",
    "# You also have a store of functions:\n",
    "list(mesh.func)\n",
    "# ['embedder', 'planarizer', 'clusterer']\n",
    "\n",
    "list(mesh.func['embedder'])  # list the embedders\n",
    "# ['constant', 'segment_based', ...]\n",
    "\n",
    "\n",
    "# write to the segments store (save some segments)\n",
    "mesh.stores['segments']['segments_3'] = ['segment6', 'segment7']\n",
    "\n",
    "# call an embedder function on a value of segments\n",
    "output_store_key, output_val_key = mesh.call(\n",
    "    mesh.func['embedder']['constant'],\n",
    "    mesh.stores['segments']['segments_3']\n",
    ")\n",
    "\n",
    "# You don't get the output: You get the reference where you can find it\n",
    "output_store = mesh.stores[output_store_key]\n",
    "output_val = output_store[output_val_key]\n",
    "assert output_val == [[1, 2, 3], [1, 2, 3]]  # because segments_3 has two segments\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6d125b52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 2, 3], [1, 2, 3], [1, 2, 3], [1, 2, 3]]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[[1,2,3]] * 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f7c6a0f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dol\n",
    "\n",
    "t = AttrDict(dol.Files('~/tmp'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ff03d1e",
   "metadata": {},
   "source": [
    "Get:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f200142b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a1ebf81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def embedder(segments: Segments) -> Embeddings:\n",
    "    \"\"\"\n",
    "    Embed the given segments into a sequence of embeddings.\n",
    "    \"\"\"\n",
    "\n",
    "def planarizer(embeddings: Embeddings) -> PlanarVectors:\n",
    "    \"\"\"\n",
    "    Convert the given embeddings into planar vectors.\n",
    "    \"\"\"\n",
    "\n",
    "def clusterer(embeddings: Embeddings, n_clusters: int) -> ClusterIndices:\n",
    "    \"\"\"\n",
    "    Cluster the given embeddings into a sequence of cluster indices.\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a424d68e",
   "metadata": {},
   "source": [
    "# DOG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e0a3b6c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Store Inspection ---\n",
      "All value stores are present.\n",
      "Initial segment data verified.\n",
      "All function types are registered.\n",
      "Embedder function implementations verified.\n",
      "New segments_3 data added successfully.\n",
      "segments_1 data updated successfully.\n",
      "segments_2 data retrieved successfully.\n",
      "segments_3 data deleted successfully.\n",
      "\n",
      "--- Function Call and Output Management ---\n",
      "Embedder function 'constant' called. Output stored at 'embeddings' with key 'output_embeddings_1'.\n",
      "Retrieved embeddings: [[1, 2, 3], [1, 2, 3]]\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 298\u001b[0m\n\u001b[1;32m    293\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRetrieved summary: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutput_val_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    295\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mAll DOG operations tested successfully!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 298\u001b[0m \u001b[43mtest_dog_operations\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[2], line 237\u001b[0m, in \u001b[0;36mtest_dog_operations\u001b[0;34m()\u001b[0m\n\u001b[1;32m    235\u001b[0m output_val_planar \u001b[38;5;241m=\u001b[39m output_store_planar[output_val_key_planar]\n\u001b[1;32m    236\u001b[0m \u001b[38;5;66;03m# Expected: (1*0.5, 2*0.5) = (0.5, 1.0) and (3*0.5, unknown*0.5) (second and third values are 2,3 for [1,2,3])\u001b[39;00m\n\u001b[0;32m--> 237\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m output_val_planar \u001b[38;5;241m==\u001b[39m [[\u001b[38;5;241m0.5\u001b[39m, \u001b[38;5;241m1.0\u001b[39m], [\u001b[38;5;241m0.5\u001b[39m, \u001b[38;5;241m1.0\u001b[39m]] \u001b[38;5;66;03m# Assumes constant embedder gave [1,2,3] for each segment\u001b[39;00m\n\u001b[1;32m    238\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlanarizer function \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124membedding_based\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m called. Output stored at \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutput_store_key_planar\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m with key \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutput_val_key_planar\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    239\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRetrieved planar vectors: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutput_val_planar\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pytest\n",
    "from typing import Callable, Any, Dict, List\n",
    "from functools import partial\n",
    "from collections.abc import MutableMapping\n",
    "from dol import Pipe\n",
    "\n",
    "# --- Mocks for demonstration ---\n",
    "# In a real scenario, these would be proper classes or enums\n",
    "class Segments: pass\n",
    "class Embeddings: pass\n",
    "class PlanarVectors: pass\n",
    "class ClusterIndices: pass\n",
    "class AnalysisReports: pass\n",
    "class Summaries: pass\n",
    "\n",
    "\n",
    "# The `vectorize` utility function\n",
    "vectorize = lambda func: Pipe(partial(map, func), list)\n",
    "\n",
    "# --- Core DOG Abstraction (Simplified for example) ---\n",
    "# This class represents the 'mk_mesh_for_funcs' output, renamed to DOG\n",
    "class DOG:\n",
    "    def __init__(self, funcs: Dict[str, Any], val_stores: Dict[str, Any], func_stores: Dict[str, Any]):\n",
    "        self.func_signatures = funcs\n",
    "        self._val_stores_config = val_stores\n",
    "        self._func_stores_config = func_stores\n",
    "        \n",
    "        # Initialize actual value stores\n",
    "        self.stores = {name: config['store'] for name, config in val_stores.items()}\n",
    "        \n",
    "        # Initialize actual function stores\n",
    "        self.func = {name: config['store'] for name, config in func_stores.items()}\n",
    "\n",
    "        # Simple counter for unique output keys\n",
    "        self._output_counter = 0\n",
    "\n",
    "    def call(self, func_impl: Callable, *inputs: Any) -> tuple[str, str]:\n",
    "        \"\"\"\n",
    "        Calls a function implementation and stores its output, returning a reference.\n",
    "        Determines the output store based on the function's expected return type.\n",
    "        \"\"\"\n",
    "        # A simple mechanism to map function outputs to specific stores based on types.\n",
    "        # In a real system, this would be more sophisticated (e.g., based on func_signatures)\n",
    "        output_type = None\n",
    "        for func_name, signature in self.func_signatures.items():\n",
    "            if func_impl in self.func[func_name].values(): # Naive lookup\n",
    "                # This needs a more robust way to map func_impl to its signature's return type\n",
    "                # For simplicity, we'll infer based on function name conventions or mock it.\n",
    "                if func_name == 'embedder':\n",
    "                    output_type = 'embeddings'\n",
    "                elif func_name == 'planarizer':\n",
    "                    output_type = 'planar_vectors'\n",
    "                elif func_name == 'clusterer':\n",
    "                    output_type = 'cluster_indices'\n",
    "                elif func_name == 'analyzer': # For new function type\n",
    "                    output_type = 'analysis_reports'\n",
    "                elif func_name == 'summarizer': # For new function type\n",
    "                    output_type = 'summaries'\n",
    "                break\n",
    "        \n",
    "        if not output_type or output_type not in self.stores:\n",
    "            raise ValueError(f\"Could not determine output store for function: {func_impl}\")\n",
    "\n",
    "        output_data = func_impl(*inputs)\n",
    "        \n",
    "        self._output_counter += 1\n",
    "        output_key = f\"output_{output_type}_{self._output_counter}\"\n",
    "        self.stores[output_type][output_key] = output_data\n",
    "        \n",
    "        return output_type, output_key\n",
    "\n",
    "# --- Test Data & Configuration ---\n",
    "\n",
    "# Extend function signatures for new capabilities\n",
    "funcs = {\n",
    "    'embedder': Callable[[Segments], Embeddings],\n",
    "    'planarizer': Callable[[Embeddings], PlanarVectors],\n",
    "    'clusterer': Callable[[Embeddings, int], ClusterIndices],\n",
    "    'analyzer': Callable[[Embeddings, PlanarVectors], AnalysisReports], # New function type\n",
    "    'summarizer': Callable[[AnalysisReports], Summaries], # Another new function type\n",
    "}\n",
    "\n",
    "# Extend value stores for new data types and initial data\n",
    "val_stores = {\n",
    "    'segments': {\n",
    "        'type': Segments,\n",
    "        'store': {\n",
    "            'segments_1': ['segment1', 'segment2', 'segment3'],\n",
    "            'segments_2': ['segment4', 'segment5']\n",
    "        },\n",
    "    },\n",
    "    'embeddings': {\n",
    "        'type': Embeddings,\n",
    "        'store': dict(), # Will store Embedding objects\n",
    "    },\n",
    "    'planar_vectors': {\n",
    "        'type': PlanarVectors,\n",
    "        'store': dict(), # Will store PlanarVector objects\n",
    "    },\n",
    "    'cluster_indices': {\n",
    "        'type': ClusterIndices,\n",
    "        'store': dict(), # Will store ClusterIndex objects\n",
    "    },\n",
    "    'analysis_reports': { # New store for analysis outputs\n",
    "        'type': AnalysisReports,\n",
    "        'store': dict(),\n",
    "    },\n",
    "    'summaries': { # New store for summary outputs\n",
    "        'type': Summaries,\n",
    "        'store': dict(),\n",
    "    },\n",
    "}\n",
    "\n",
    "# Extend function implementations\n",
    "func_stores = {\n",
    "    'embedder': {\n",
    "        'name': 'embedders',\n",
    "        'store': {\n",
    "            'constant': lambda segments: vectorize(lambda s: [1, 2, 3])(segments),\n",
    "            'segment_based': lambda segments: vectorize(lambda s: [len(s), 0.5, 0.5])(segments),\n",
    "        },\n",
    "    },\n",
    "    'planarizer': {\n",
    "        'name': 'planarizers',\n",
    "        'store': {\n",
    "            'constant': lambda embeddings: vectorize(lambda e: (e[0], e[1]))(embeddings),\n",
    "            'embedding_based': lambda embeddings: vectorize(lambda e: (e[0] * 0.5, e[1] * 0.5))(embeddings),\n",
    "        },\n",
    "    },\n",
    "    'clusterer': {\n",
    "        'name': 'clusterers',\n",
    "        'store': {\n",
    "            'kmeans': lambda embeddings, num_clusters: ['cluster_a', 'cluster_b'] * (len(embeddings) // 2 + len(embeddings) % 2),\n",
    "            'dbscan': lambda embeddings, min_points: ['noise'] * len(embeddings),\n",
    "        },\n",
    "    },\n",
    "    'analyzer': { # New analyzer functions\n",
    "        'name': 'analyzers',\n",
    "        'store': {\n",
    "            'similarity_scorer': lambda embeddings, planar_vectors: [{'score': (e[0] + p[0]) / 2} for e, p in zip(embeddings, planar_vectors)],\n",
    "            'complex_report_generator': lambda embeddings, planar_vectors: {'report_id': 'complex-123', 'summary': 'Detailed analysis'},\n",
    "        },\n",
    "    },\n",
    "    'summarizer': { # New summarizer functions\n",
    "        'name': 'summarizers',\n",
    "        'store': {\n",
    "            'text_summary': lambda reports: \"Overall summary from reports\",\n",
    "            'key_metric_extractor': lambda reports: {'total_score': sum(r.get('score', 0) for r in reports)},\n",
    "        },\n",
    "    },\n",
    "}\n",
    "\n",
    "\n",
    "# --- The User Story Test ---\n",
    "\n",
    "def test_dog_operations():\n",
    "    # Instantiate the DOG\n",
    "    # We initialize our Data Operation Graph (DOG) with the defined function signatures,\n",
    "    # value stores, and function implementations.\n",
    "    dog_instance = DOG(funcs=funcs, val_stores=val_stores, func_stores=func_stores)\n",
    "\n",
    "    # --- Store Inspection ---\n",
    "    # We want to check if all expected value stores are accessible.\n",
    "    print(\"\\n--- Store Inspection ---\")\n",
    "    assert sorted(list(dog_instance.stores.keys())) == sorted(['segments', 'embeddings', 'planar_vectors', 'cluster_indices', 'analysis_reports', 'summaries'])\n",
    "    print(\"All value stores are present.\")\n",
    "\n",
    "    # We expect the 'segments' store to have its initial data.\n",
    "    assert 'segments_1' in dog_instance.stores['segments']\n",
    "    assert dog_instance.stores['segments']['segments_1'] == ['segment1', 'segment2', 'segment3']\n",
    "    print(\"Initial segment data verified.\")\n",
    "\n",
    "    # We want to verify that all expected function types are registered.\n",
    "    assert sorted(list(dog_instance.func.keys())) == sorted(['embedder', 'planarizer', 'clusterer', 'analyzer', 'summarizer'])\n",
    "    print(\"All function types are registered.\")\n",
    "\n",
    "    # We want to check if specific function implementations for 'embedder' are available.\n",
    "    assert 'constant' in dog_instance.func['embedder']\n",
    "    assert 'segment_based' in dog_instance.func['embedder']\n",
    "    print(\"Embedder function implementations verified.\")\n",
    "\n",
    "    # --- CRUD Operations on Stores ---\n",
    "\n",
    "    # We want to add new data to an existing store.\n",
    "    dog_instance.stores['segments']['segments_3'] = ['segment6', 'segment7']\n",
    "    assert 'segments_3' in dog_instance.stores['segments']\n",
    "    assert dog_instance.stores['segments']['segments_3'] == ['segment6', 'segment7']\n",
    "    print(\"New segments_3 data added successfully.\")\n",
    "\n",
    "    # We want to update existing data in a store.\n",
    "    dog_instance.stores['segments']['segments_1'] = ['updated_segment_A', 'updated_segment_B']\n",
    "    assert dog_instance.stores['segments']['segments_1'] == ['updated_segment_A', 'updated_segment_B']\n",
    "    print(\"segments_1 data updated successfully.\")\n",
    "\n",
    "    # We want to read data from a store.\n",
    "    retrieved_segments = dog_instance.stores['segments']['segments_2']\n",
    "    assert retrieved_segments == ['segment4', 'segment5']\n",
    "    print(\"segments_2 data retrieved successfully.\")\n",
    "\n",
    "    # We want to delete data from a store.\n",
    "    del dog_instance.stores['segments']['segments_3']\n",
    "    assert 'segments_3' not in dog_instance.stores['segments']\n",
    "    print(\"segments_3 data deleted successfully.\")\n",
    "\n",
    "    # --- Function Call and Output Management ---\n",
    "\n",
    "    # We want to call an 'embedder' function ('constant') on existing segment data\n",
    "    # and ensure its output is correctly stored and referenced.\n",
    "    print(\"\\n--- Function Call and Output Management ---\")\n",
    "    segments_to_embed = dog_instance.stores['segments']['segments_1'] # Using updated segments_1\n",
    "    output_store_key_embed, output_val_key_embed = dog_instance.call(\n",
    "        dog_instance.func['embedder']['constant'],\n",
    "        segments_to_embed\n",
    "    )\n",
    "\n",
    "    # We expect the output to be in the 'embeddings' store.\n",
    "    assert output_store_key_embed == 'embeddings'\n",
    "    output_store_embed = dog_instance.stores[output_store_key_embed]\n",
    "    output_val_embed = output_store_embed[output_val_key_embed]\n",
    "    # segments_1 has 2 items, so constant embedder should produce 2 outputs\n",
    "    assert output_val_embed == [[1, 2, 3], [1, 2, 3]]\n",
    "    print(f\"Embedder function 'constant' called. Output stored at '{output_store_key_embed}' with key '{output_val_key_embed}'.\")\n",
    "    print(f\"Retrieved embeddings: {output_val_embed}\")\n",
    "\n",
    "    # We want to call a 'planarizer' function ('embedding_based') on the newly generated embeddings.\n",
    "    # This demonstrates chaining operations using store references.\n",
    "    output_store_key_planar, output_val_key_planar = dog_instance.call(\n",
    "        dog_instance.func['planarizer']['embedding_based'],\n",
    "        output_val_embed # Using the actual value from the previous step\n",
    "    )\n",
    "\n",
    "    # We expect the output to be in the 'planar_vectors' store.\n",
    "    assert output_store_key_planar == 'planar_vectors'\n",
    "    output_store_planar = dog_instance.stores[output_store_key_planar]\n",
    "    output_val_planar = output_store_planar[output_val_key_planar]\n",
    "    # Expected: (1*0.5, 2*0.5) = (0.5, 1.0) and (3*0.5, unknown*0.5) (second and third values are 2,3 for [1,2,3])\n",
    "    assert output_val_planar == [[0.5, 1.0], [0.5, 1.0]] # Assumes constant embedder gave [1,2,3] for each segment\n",
    "    print(f\"Planarizer function 'embedding_based' called. Output stored at '{output_store_key_planar}' with key '{output_val_key_planar}'.\")\n",
    "    print(f\"Retrieved planar vectors: {output_val_planar}\")\n",
    "\n",
    "    # We want to call a 'clusterer' function ('kmeans') using the generated embeddings\n",
    "    # and a direct integer input.\n",
    "    num_clusters = 2\n",
    "    output_store_key_cluster, output_val_key_cluster = dog_instance.call(\n",
    "        dog_instance.func['clusterer']['kmeans'],\n",
    "        output_val_embed, # Embeddings from previous step\n",
    "        num_clusters      # Direct integer input\n",
    "    )\n",
    "\n",
    "    # We expect the output to be in the 'cluster_indices' store.\n",
    "    assert output_store_key_cluster == 'cluster_indices'\n",
    "    output_store_cluster = dog_instance.stores[output_store_key_cluster]\n",
    "    output_val_cluster = output_store_cluster[output_val_key_cluster]\n",
    "    # Expected: 2 segments -> ['cluster_a', 'cluster_b']\n",
    "    assert output_val_cluster == ['cluster_a', 'cluster_b']\n",
    "    print(f\"Clusterer function 'kmeans' called. Output stored at '{output_store_key_cluster}' with key '{output_val_key_cluster}'.\")\n",
    "    print(f\"Retrieved cluster indices: {output_val_cluster}\")\n",
    "\n",
    "    # --- Demonstrating New Function Calls and Chaining ---\n",
    "\n",
    "    # We want to call the new 'analyzer' function ('similarity_scorer') using two different data stores as input.\n",
    "    print(\"\\n--- Demonstrating Advanced Chaining ---\")\n",
    "    output_store_key_analyze, output_val_key_analyze = dog_instance.call(\n",
    "        dog_instance.func['analyzer']['similarity_scorer'],\n",
    "        output_val_embed, # Embeddings\n",
    "        output_val_planar # Planar vectors\n",
    "    )\n",
    "\n",
    "    assert output_store_key_analyze == 'analysis_reports'\n",
    "    output_store_analyze = dog_instance.stores[output_store_key_analyze]\n",
    "    output_val_analyze = output_store_analyze[output_val_key_analyze]\n",
    "    # Based on embeddings [[1,2,3],[1,2,3]] and planar_vectors [[0.5,1.0],[0.5,1.0]]\n",
    "    # Expecting [ (1+0.5)/2, (1+0.5)/2 ] -> [0.75, 0.75]\n",
    "    expected_scores = [{'score': 0.75}, {'score': 0.75}]\n",
    "    # The current mock 'planarizer' constant returns (e[0], e[1]), meaning [1,2,3] -> (1,2)\n",
    "    # Then planar_vectors are [0.5, 1.0] from [1,2]. So the scores are (1+0.5)/2 = 0.75\n",
    "    assert output_val_analyze == expected_scores\n",
    "    print(f\"Analyzer function 'similarity_scorer' called. Output stored at '{output_store_key_analyze}' with key '{output_val_key_analyze}'.\")\n",
    "    print(f\"Retrieved analysis reports: {output_val_analyze}\")\n",
    "\n",
    "\n",
    "    # We want to call the new 'summarizer' function ('text_summary') on the analysis reports.\n",
    "    output_store_key_summary, output_val_key_summary = dog_instance.call(\n",
    "        dog_instance.func['summarizer']['text_summary'],\n",
    "        output_val_analyze\n",
    "    )\n",
    "\n",
    "    assert output_store_key_summary == 'summaries'\n",
    "    output_store_summary = dog_instance.stores[output_store_key_summary]\n",
    "    output_val_summary = output_store_summary[output_val_key_summary]\n",
    "    assert output_val_summary == \"Overall summary from reports\"\n",
    "    print(f\"Summarizer function 'text_summary' called. Output stored at '{output_store_key_summary}' with key '{output_val_key_summary}'.\")\n",
    "    print(f\"Retrieved summary: '{output_val_summary}'\")\n",
    "\n",
    "    print(\"\\nAll DOG operations tested successfully!\")\n",
    "\n",
    "\n",
    "test_dog_operations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eed51881",
   "metadata": {},
   "outputs": [],
   "source": [
    "import strand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b230b5e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['updated_segment_A', 'updated_segment_B']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dog_instance.stores['segments']['segments_1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5a2ecb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import au"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f07c5efe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efd63d55",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daea9d9d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "802a64e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bda29138",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "p10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
